{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e62a3f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import AppLayout\n",
    "import IPython.display as pyDis\n",
    "\n",
    "from context import community_module\n",
    "from community_module.community_detection.similarityCommunityDetection import SimilarityCommunityDetection\n",
    "from community_module.similarity.emotionSimilarity import EmotionSimilarity\n",
    "from community_module.visualization.gephiVisualization import GephiVisualization\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af490b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Leemos los ficheros de respuestas de usuarios\n",
    "users_df = pd.read_csv('../../data/MNCN/user_profiles.csv')\n",
    "users_grouped_df = pd.read_csv('../../data/MNCN/user_profiles_grouped.csv')\n",
    "\n",
    "# Datos necesarios para los filtros\n",
    "q103_index = list(range(1,7))\n",
    "q107a_index = list(range(7, 13))\n",
    "q107b_index = list(range(13, 16))\n",
    "q110a_index = list(range(16, 18))\n",
    "q110b_index = list(range(18, len(users_df.columns)))\n",
    "\n",
    "# Questions\n",
    "questions = {\n",
    "    'q103': q103_index,\n",
    "    'q107a': q107a_index,\n",
    "    'q107b': q107b_index,\n",
    "    'q110a': q110a_index,\n",
    "    'q110b': q110b_index\n",
    "}\n",
    "\n",
    "# Explains index\n",
    "explain_indexes = {\n",
    "    'q103': [7, 9],\n",
    "    'q107a': [5, 6],\n",
    "    'q107b': [8],\n",
    "    'q110a': [],\n",
    "    'q110b': []\n",
    "}\n",
    "\n",
    "# Diccionario de respuestas\n",
    "answers = {\n",
    "    'q103_0': 'Reducir el tiempo de la ducha',\n",
    "    'q103_1': 'Comprar menos ropa',\n",
    "    'q103_2': 'No usar productos con muchos envases',\n",
    "    'q103_3': 'Ir a pie a más sitios',\n",
    "    'q103_4': 'Reducir los residuos que genero',\n",
    "    'q103_5': 'Reciclar de forma correcta',\n",
    "    'q107a_0': 'En coche',\n",
    "    'q107a_1': 'Andando',\n",
    "    'q107a_2': 'En bicicleta',\n",
    "    'q107a_3': 'En autobús',\n",
    "    'q107a_4': 'En metro',\n",
    "    'q107a_5': 'En patinete',\n",
    "    'q107b_0': 'Estaría dispuesto a cambiar de medio de transporte',\n",
    "    'q107b_1': 'No estaría dispuesto a cambiar de medio de transporte',\n",
    "    'q107b_2': 'Quizá estaría dispuesto a cambiar de medio de transporte',\n",
    "    'q110a_0': 'Si he tenido una mascota exótica',\n",
    "    'q110a_1': 'No he tenido una mascota exótica',\n",
    "    'q110b_0': 'Adoptaria una totuga de florida',\n",
    "    'q110b_1': 'Adoptaria un perro común',\n",
    "    'q110b_2': 'Adoptaria un gato común',\n",
    "    'q110b_3': 'Adoptaria una cotorra argentina',\n",
    "    'q110b_4': 'Adoptaria una cacatúa',\n",
    "    'q110b_5': 'Adoptaria un mono capuchino',\n",
    "}\n",
    "\n",
    "# Funcion de similitud y n clusters a detectar\n",
    "sim = 'cosine'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "469c165d",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_to_explain_df = None\n",
    "users_groups_df = None\n",
    "\n",
    "def search_groups(data, indexes, explains, percentage=1):\n",
    "    # Comprobamos que no hay algún usuario que solo contenga ceros\n",
    "    filter_no_answers = data.apply(lambda x: x.values.sum() != 0, axis=1)\n",
    "    correct_data = data[filter_no_answers]\n",
    "    correct_explains = explains[filter_no_answers]\n",
    "\n",
    "    n_clusters = 2\n",
    "    finish_search = False\n",
    "\n",
    "    while not finish_search:\n",
    "\n",
    "        #print(\"Clusters:\", n_clusters)\n",
    "        community_detection = SimilarityCommunityDetection(correct_data)\n",
    "        result = community_detection.calculate_communities(metric=sim, n_clusters=n_clusters)\n",
    "\n",
    "        correct_data['group'] = result.values()\n",
    "        correct_explains['group'] = correct_data['group']\n",
    "\n",
    "        # Comprobamos que para cada grupo tenemos al menos, una respuesta común\n",
    "        # answers_per_group_df = correct_data.groupby(by='group').sum().reset_index()\n",
    "        answers_per_group_df = correct_explains.groupby(by='group').sum().reset_index()\n",
    "        max_answers_per_group = answers_per_group_df.apply(lambda x: np.max(x[1:].values), axis=1).values\n",
    "\n",
    "        #print(\"Max answers:\", max_answers_per_group.values)\n",
    "\n",
    "        members_per_group = correct_explains.groupby(by='group').count().iloc[:,0].values\n",
    "        min_same_answers_per_group = np.round(members_per_group * percentage)\n",
    "\n",
    "        finish_search = np.greater_equal(max_answers_per_group, min_same_answers_per_group).sum() == len(members_per_group)\n",
    "\n",
    "        if not finish_search:\n",
    "            n_clusters += 1\n",
    "\n",
    "    # Genero un DF para extraer las explicaciones de los grupos\n",
    "    groups_to_explain_df = correct_explains.groupby(by='group').sum().reset_index()\n",
    "    groups_to_explain_df['members'] = members_per_group\n",
    "\n",
    "    # Genero la tabla de usuario/grupo\n",
    "    result_df = pd.DataFrame.from_dict(result, orient='index', columns=['group'])\n",
    "    users_group = users_df.join(result_df)\n",
    "    \n",
    "    return groups_to_explain_df, users_group\n",
    "\n",
    "def explain_groups(groups_to_explain_df):\n",
    "    for i in range(len(groups_to_explain_df)):\n",
    "\n",
    "        if int(groups_to_explain_df.iloc[i]['members']) >= 2:\n",
    "            row = groups_to_explain_df.iloc[i]\n",
    "            max_value = row[1:-1].max()\n",
    "\n",
    "            row_ans = row[1:-1]\n",
    "            row_ans = row_ans[row_ans == max_value]\n",
    "\n",
    "            print(\"-----------\")\n",
    "            print(\"## GROUP\", i)\n",
    "            print(\"# N. MEMBERS:\", int(groups_to_explain_df.iloc[i]['members']))\n",
    "            print(\"# COMMON PROPERTIES:\")\n",
    "\n",
    "            for r in row_ans.index.values:\n",
    "                print(\"  -\", r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06bb1d98",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cefac9bdc134f82a8fa2fdd9e266e96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "AppLayout(children=(Button(description='Buscar', layout=Layout(grid_area='footer'), style=ButtonStyle()), Sele…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users without groups: 5\n",
      "-----------\n",
      "## GROUP 0\n",
      "# N. MEMBERS: 3\n",
      "# COMMON PROPERTIES:\n",
      "  - Reduce Consumption\n",
      "  - Recycle\n",
      "-----------\n",
      "## GROUP 1\n",
      "# N. MEMBERS: 30\n",
      "# COMMON PROPERTIES:\n",
      "  - Reduce Consumption\n",
      "-----------\n",
      "## GROUP 2\n",
      "# N. MEMBERS: 2\n",
      "# COMMON PROPERTIES:\n",
      "  - Reduce Consumption\n",
      "-----------\n",
      "## GROUP 3\n",
      "# N. MEMBERS: 4\n",
      "# COMMON PROPERTIES:\n",
      "  - Reduce Consumption\n",
      "  - Recycle\n",
      "-----------\n",
      "## GROUP 5\n",
      "# N. MEMBERS: 7\n",
      "# COMMON PROPERTIES:\n",
      "  - Reduce Consumption\n",
      "  - Recycle\n",
      "  - Change Transport\n",
      "-----------\n",
      "## GROUP 7\n",
      "# N. MEMBERS: 3\n",
      "# COMMON PROPERTIES:\n",
      "  - Recycle\n",
      "  - Change Transport\n",
      "-----------\n",
      "## GROUP 8\n",
      "# N. MEMBERS: 3\n",
      "# COMMON PROPERTIES:\n",
      "  - Reduce Consumption\n",
      "  - Recycle\n",
      "  - Change Transport\n",
      "-----------\n",
      "## GROUP 12\n",
      "# N. MEMBERS: 4\n",
      "# COMMON PROPERTIES:\n",
      "  - Reduce Consumption\n",
      "  - Change Transport\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Preparo la interfaz\n",
    "questions_wid = widgets.SelectMultiple(\n",
    "    options=list(questions.keys()),\n",
    "    descriptions='Seleccionar preguntas',\n",
    "    disable=False\n",
    ")\n",
    "\n",
    "percentage_wid = widgets.FloatSlider(\n",
    "    value=0.94,\n",
    "    min=0.0,\n",
    "    max=1.0,\n",
    "    step=0.01,\n",
    "    description='Min % respuestas comunes'\n",
    ")\n",
    "\n",
    "button = widgets.Button(\n",
    "    description = 'Buscar'\n",
    ")\n",
    "\n",
    "\n",
    "def btn_event(obj):\n",
    "    # Incluimos los índices de las preguntas seleccionadas\n",
    "    indexes = list()\n",
    "    indexes_explains = list()\n",
    "    \n",
    "    for q in questions_wid.value:\n",
    "        indexes.extend(questions[q])\n",
    "        indexes_explains.extend(explain_indexes[q])\n",
    "        \n",
    "    # Filtramos el dataset, seleccionando solo las preguntas que queremos\n",
    "    data = users_df.iloc[:,indexes]\n",
    "    explains = users_grouped_df.iloc[:,indexes_explains]\n",
    "    \n",
    "    # Aplicamos la búsqueda de grupos\n",
    "    groups_to_explain_df, users_groups_df = search_groups(data, indexes, explains, percentage=percentage_wid.value)\n",
    "    \n",
    "    # TODO: Aquí filtrar grupos por número mínimo de miembros\n",
    "    # Obtenemos los ids de grupos que queremos eliminar (menos de 2 usuarios)\n",
    "    filter_groups = users_groups_df.groupby(by='group').count()['UserId'] < 2\n",
    "    groups_to_filter = filter_groups.index.values[filter_groups]\n",
    "    \n",
    "    # Imprimir el número de usuarios que se filtran\n",
    "    # Quitamos el grupo del dataset\n",
    "    users_out = users_groups_df[users_groups_df['group'].isin(groups_to_filter)].index.values\n",
    "    print('Users without groups:', len(users_out))\n",
    "    users_groups_df = users_groups_df[~users_groups_df['group'].isin(groups_to_filter)]\n",
    "    \n",
    "    # Explicamos los grupos obtenidos\n",
    "    explain_groups(groups_to_explain_df)\n",
    "    \n",
    "    # Pintamos en Gephi\n",
    "    gv = GephiVisualization()\n",
    "    \n",
    "    # Preparamos los datos de usuarios y distancias\n",
    "    users = users_groups_df[['UserId', 'School', 'Grade', 'Type', 'Zone', 'group']].values\n",
    "    data = data[~data.index.isin(users_out)]\n",
    "    distances = cosine_similarity(data)\n",
    "    \n",
    "    gv.load_community(users, distances, users_properties=['School', 'Grade', 'Type', 'Zone', 'community'])\n",
    "    \n",
    "button.on_click(btn_event)\n",
    "AppLayout(hader=None, left_sidebar=questions_wid, center=None, right_sidebar=percentage_wid, footer=button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bc2076",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
